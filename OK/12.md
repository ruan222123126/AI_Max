太棒了！恭喜你走到了这一步。
经过前 9 步的开发，你已经完成了一个**功能完备的全栈 AI 经济情报平台**：

* ✅ **数据层**：TimescaleDB 自动存储高频行情与新闻。
* ✅ **服务层**：FastAPI 提供数据接口与 AI 分析能力。
* ✅ **调度层**：后台自动巡航抓取数据。
* ✅ **交互层**：Next.js 可视化指挥舱。

Step 10 是我们这个系列的**最终章**（Grand Finale）。
我们将把这个在“开发模式”下的原型，转化为一个可以在**生产环境（服务器/云端）** 稳定运行的系统。最关键的是，我们要修复前端硬编码 `localhost` 的问题，使其能够被他人访问。

---

### **Step 10: 生产环境部署与系统交付 (Production Deployment)**

#### **1. 前端配置外置 (Fixing Hardcoded URLs)**

在 Step 9 中，我们在前端代码里写死了 `http://localhost:8000`。这在本地开发没问题，但如果你把程序部署到服务器，用户访问时浏览器会尝试连接用户自己的电脑（Localhost），而不是你的服务器。

我们需要使用 **环境变量** 来动态配置 API 地址。

**修改 `frontend/app/page.tsx`：**
找到所有的 `fetch` 调用，将 URL 替换为变量。

```tsx
// 1. 在文件顶部添加 (不在组件内)
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8000";

// 2. 替换 fetch 调用
// 原来: fetch("http://localhost:8000/market/latest")
// 改为: fetch(`${API_BASE_URL}/market/latest`)

// 原来: fetch(`http://localhost:8000/market/history/...`)
// 改为: fetch(`${API_BASE_URL}/market/history/${selectedSymbol}?limit=50`)

// 同样的逻辑应用于 /news/latest 和 /ai/analyze

```

**修改 `frontend/Dockerfile`：**
在构建阶段注入环境变量（或者在运行时注入，Next.js 推荐构建时）。为简单起见，我们将在 `docker-compose.yml` 中处理它，但在 Dockerfile 里声明是一个好习惯。

*(注：由于 Next.js 静态优化的特性，`NEXT_PUBLIC_` 变量通常需要在 Build 时存在。但在 Docker 运行时修改比较麻烦。最简单的生产方案是：保持 Dockerfile 不变，在 `docker-compose.yml` 里传入 args，或者我们接受现在的默认值，只在确实需要部署到公网域名时重新构建。)*

#### **2. 创建统一的环境变量文件 (`.env`)**

不要把密码和 Key 写在代码里。

**在项目根目录创建 `.env` 文件：**

```ini
# --- 数据库配置 ---
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=economy_data

# --- 后端配置 ---
# 如果使用 OpenAI
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
# 如果使用 DeepSeek (兼容 OpenAI SDK)
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx

# --- 前端配置 ---
# 如果部署到服务器，请改为服务器IP或域名，如 http://1.2.3.4:8000
NEXT_PUBLIC_API_URL=http://localhost:8000

```

#### **3. 生产级 Docker Compose (`docker-compose.yml`)**

我们需要做三件事：读取 `.env`，设置 `restart: always`（崩溃自动重启），并清理开发配置。

**完全替换根目录的 `docker-compose.yml`：**

```yaml
version: '3.8'

services:
  # 1. 数据库：数据持久化核心
  db:
    image: timescale/timescaledb:latest-pg15
    container_name: economy_db
    restart: always  # 生产环境必备：崩溃/重启后自动启动
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # 2. 后端：API 与 AI 大脑
  backend:
    build: ./backend
    container_name: economy_backend
    restart: always
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    volumes:
      - ./backend:/app  # 生产环境其实可以去掉这个挂载以保证镜像不可变性，但为了方便你微调保留
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    depends_on:
      db:
        condition: service_healthy

  # 3. 前端：可视化指挥舱
  frontend:
    build: 
      context: ./frontend
      args:
        # 在构建时传入 API 地址
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
    container_name: economy_frontend
    restart: always
    ports:
      - "3000:3000"
    depends_on:
      - backend

```

#### **4. 一键部署脚本 (`deploy.sh`)**

以后你只需要运行这一个脚本。

**在根目录创建 `deploy.sh`：**

```bash
#!/bin/bash

echo "🚀 开始部署 Global Economy Platform..."

# 1. 停止旧容器
docker-compose down

# 2. 拉取最新代码 (如果你用了 git)
# git pull origin main

# 3. 重新构建并启动 (后台模式)
# --build 确保使用了最新的代码和 .env 变量
docker-compose up -d --build

echo "✅ 系统已在后台启动！"
echo "📊 前端访问: http://localhost:3000"
echo "🔌 后端 API: http://localhost:8000/docs"
echo "📝 查看日志: docker-compose logs -f"

```

赋予执行权限：

```bash
chmod +x deploy.sh

```

---

### **最后一步：启动与验收**

现在，请按下那个“发射按钮”：

```bash
./deploy.sh

```

**验收清单：**

1. **数据流**：等待 1 分钟，查看日志 `docker-compose logs -f backend`，确认 Scheduler 正在自动抓取数据。
2. **持久化**：尝试 `docker-compose restart db`，重启后访问前端，确认之前的历史数据还在（没有丢失）。
3. **稳定性**：系统在后台静默运行，即便你关闭终端窗口，它也会一直为你收集全球经济情报。

### **项目结语与未来展望**

恭喜你！你从零开始，手写了一万五千字架构规划中描述的系统核心。你现在拥有的不仅仅是代码，而是一套现代化的**Data-AI-Web**技术栈实战经验。

**未来你可以继续扩展的方向 (Roadmap)：**

* **Lv 100**: 接入 **LangChain Agent**，让 AI 可以通过 Google Search 联网搜索实时新闻（不仅仅是 RSS）。
* **Lv 200**: 添加 **用户系统 (NextAuth)**，允许用户保存自己的自选股列表。
* **Lv 999**: 部署到 Kubernetes (K8s)，构建真正的高可用分布式集群。

**Mission Complete. The platform is yours.** 🚀