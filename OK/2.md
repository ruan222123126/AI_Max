太棒了，这种执行力是项目成功的关键。

既然基础设施已经就绪，Step 2 的目标非常明确：**让数据流动起来**。我们将编写一个独立的 Python 脚本，使用 `yfinance` 抓取实时市场数据，并将其存入我们在 Step 1 中创建的 TimescaleDB 超表中。

以下是 Step 2 的完整执行流程：

### Step 2: 构建数据采集模块 (Data Ingestion)

#### 1. 更新依赖配置

我们需要添加 `yfinance` 库来获取数据。

**修改 `backend/requirements.txt`：**
在文件末尾添加一行 `yfinance`。

```text
fastapi
uvicorn
asyncpg
sqlalchemy
yfinance

```

#### 2. 创建脚本目录与采集脚本

为了保持项目整洁，我们在 backend 目录下创建一个专门存放脚本的文件夹。

**在终端执行：**

```bash
mkdir -p global-economy-platform/backend/scripts

```

**创建文件 `backend/scripts/ingest_market_data.py`：**
这个脚本将模拟一个“数据生产者”，抓取股票和加密货币的最新价格并写入数据库。

```python
import asyncio
import os
import yfinance as yf
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import text
import datetime

# 定义我们要抓取的资产列表
SYMBOLS = ["AAPL", "GOOGL", "MSFT", "BTC-USD", "ETH-USD", "EURUSD=X"]

# 从环境变量获取数据库连接，如果没有则使用默认值（适配 Docker 环境）
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+asyncpg://user:password@db:5432/economy_data")

async def fetch_and_insert():
    print(f"[{datetime.datetime.now()}] 开始采集数据...")
    
    # 1. 使用 yfinance 批量获取数据
    # period="1d" 获取最近一天的数据，interval="1m" 获取分钟级数据
    tickers = yf.Tickers(" ".join(SYMBOLS))
    
    data_to_insert = []
    current_time = datetime.datetime.now(datetime.timezone.utc)

    for symbol in SYMBOLS:
        try:
            ticker = tickers.tickers[symbol]
            # 获取最新的市场价格（有些资产可能没有 regularMarketPrice，尝试 history）
            # 为了演示，我们取 fast_info 或者最近一分钟的 history
            hist = ticker.history(period="1d", interval="1m")
            
            if not hist.empty:
                latest_price = hist['Close'].iloc[-1]
                # 注意：这里我们使用当前时间作为入库时间，也可以使用 hist 的索引时间
                data_to_insert.append({
                    "time": current_time,
                    "symbol": symbol,
                    "price": float(latest_price)
                })
                print(f"  -> 获取到 {symbol}: {latest_price}")
            else:
                print(f"  -> ⚠️ {symbol} 无数据")
                
        except Exception as e:
            print(f"  -> ❌ 获取 {symbol} 失败: {e}")

    if not data_to_insert:
        print("没有获取到任何数据，终止写入。")
        return

    # 2. 写入数据库
    engine = create_async_engine(DATABASE_URL, echo=False)
    
    try:
        async with engine.begin() as conn:
            # 构建批量插入 SQL
            # 注意：TimescaleDB/Postgres 的 TIMESTAMPTZ 需要标准的 datetime 对象
            for item in data_to_insert:
                await conn.execute(
                    text("INSERT INTO market_ticks (time, symbol, price) VALUES (:time, :symbol, :price)"),
                    item
                )
            print(f"✅ 成功写入 {len(data_to_insert)} 条数据到 TimescaleDB")
    except Exception as e:
        print(f"❌ 数据库写入失败: {e}")
    finally:
        await engine.dispose()

if __name__ == "__main__":
    # 运行异步任务
    asyncio.run(fetch_and_insert())

```

#### 3. 重建并运行

因为我们修改了 `requirements.txt`，必须重新构建 Docker 镜像。

**在 `global-economy-platform` 根目录下执行：**

1. **重建后端镜像：**
```bash
docker-compose build backend

```


2. **启动服务（如果之前关了）：**
```bash
docker-compose up -d

```


3. **运行采集脚本：**
我们不需要进入容器，直接通过 `docker-compose exec` 在正在运行的 backend 容器中执行脚本。
```bash
docker-compose exec backend python scripts/ingest_market_data.py

```



#### 4. 验证数据 (关键步骤)

脚本跑完显示“✅ 成功写入...”后，我们需要去数据库里亲眼确认。

**通过 SQL 查询验证：**

```bash
docker-compose exec db psql -U user -d economy_data -c "SELECT * FROM market_ticks ORDER BY time DESC LIMIT 10;"

```

如果你能看到类似下面的输出，Step 2 就大功告成了！

```text
             time              | symbol  |   price    
-------------------------------+---------+------------
 2024-01-18 08:30:05.123+00    | BTC-USD | 42500.50
 ...

```

---

**任务清单：**

1. [ ] 修改 `requirements.txt`
2. [ ] 创建 `backend/scripts/ingest_market_data.py`
3. [ ] `docker-compose build` & `up`
4. [ ] 运行脚本并截图/复制 SQL 查询结果

等你搞定这一步，我们就真正拥有了“有血有肉”的数据层，接下来就可以考虑 Step 3：让后端 API 把这些数据吐出来给前端了。快去执行吧！